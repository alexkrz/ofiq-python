{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexkrz/ofiq-python/blob/main/notebooks/face-occlusion-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAv6t0FKYizh"
      },
      "source": [
        "# Notebook to visualize computation of Landmarked Region"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alexkrz/ofiq-python.git\n",
        "%cd ofiq-python/notebooks/\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "4c-2gac6Yx8m",
        "outputId": "bf282cb7-6825-4e63-87d1-888f88c1a184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ofiq-python' already exists and is not an empty directory.\n",
            "/content/ofiq-python/ofiq-python/notebooks\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.19.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.1.21)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrtVVZ49Yizh"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VSZbdCRaYizh",
        "outputId": "954c5302-9219-4a15-c8f7-2c5142ca203c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from copy import deepcopy\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "from src.adnet import compute_landmarks\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOuDRoZYizi"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Kw_1aavoYizi",
        "outputId": "ee8dbaf8-bced-4edf-997c-a9d01a1334b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NoSuchFile",
          "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from ../checkpoints/adnet/adnet_ofiq.onnx failed:Load model ../checkpoints/adnet/adnet_ofiq.onnx failed. File doesn't exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_2617/3776374855.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/ColorFERET-00472_940519_hr_small_cropped.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../checkpoints/adnet/adnet_ofiq.onnx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(landmarks.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ofiq-python/src/adnet.py\u001b[0m in \u001b[0;36mcompute_landmarks\u001b[0;34m(img_p, model_p)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# model = cv2.dnn.readNetFromONNX(model_p)  # Cannot read ADNet model with OpenCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mort_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inference_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m_create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_config_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_config_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from ../checkpoints/adnet/adnet_ofiq.onnx failed:Load model ../checkpoints/adnet/adnet_ofiq.onnx failed. File doesn't exist"
          ]
        }
      ],
      "source": [
        "img_p = \"../data/ColorFERET-00472_940519_hr_small_cropped.png\"\n",
        "model_p = \"../checkpoints/adnet/adnet_ofiq.onnx\"\n",
        "landmarks = compute_landmarks(img_p, model_p)\n",
        "# print(landmarks.shape)\n",
        "\n",
        "# Helper function\n",
        "\n",
        "\n",
        "def draw_points(img: np.ndarray, points: np.ndarray, name: str = \"default\"):\n",
        "    for idx in range(len(points)):\n",
        "        x, y = points[idx]\n",
        "        cv2.circle(img, (x, y), 3, (255, 0, 0), cv2.FILLED)\n",
        "        cv2.putText(img, name, (x + 2, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "    return img\n",
        "\n",
        "\n",
        "# Show computed landmarks\n",
        "img = cv2.imread(img_p)\n",
        "width, height, channels = img.shape\n",
        "img_landmarks = deepcopy(img)\n",
        "for idx in range(len(landmarks)):\n",
        "    x, y = landmarks[idx]\n",
        "    cv2.circle(img_landmarks, (x, y), 3, (255, 0, 0), cv2.FILLED)\n",
        "    cv2.putText(img_landmarks, str(idx), (x + 2, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "plt.imshow(cv2.cvtColor(img_landmarks, cv2.COLOR_BGR2RGB))\n",
        "plt.savefig(\"../output/01_landmarks.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD8XjM_9Yizi"
      },
      "source": [
        "### Break down GetFaceMask() function into individual parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOk0aOdKYizi"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Select eyes_midpoint, chin and contour landmarks\n",
        "\n",
        "alpha = 0.0\n",
        "width, height, channels = img.shape\n",
        "\n",
        "left_eye_corners = np.stack([landmarks[60], landmarks[64]])\n",
        "right_eye_corners = np.stack([landmarks[68], landmarks[72]])\n",
        "\n",
        "eye_corners = np.concatenate([left_eye_corners, right_eye_corners])\n",
        "eyes_midpoint = np.sum(eye_corners, axis=0) / len(eye_corners)\n",
        "eyes_midpoint = eyes_midpoint.astype(\"int\")\n",
        "eyes_midpoint = eyes_midpoint[None, :]  # Add extra dimension\n",
        "\n",
        "chin = landmarks[16]\n",
        "chin = chin[None, :]  # Add extra dimension\n",
        "contour_indices = [0, 7, 25, 32]\n",
        "contour_points = []\n",
        "for idx in contour_indices:\n",
        "    contour_points.append(landmarks[idx])\n",
        "contour = np.array(contour_points)\n",
        "\n",
        "# Drawing function\n",
        "img_out = deepcopy(img)\n",
        "img_out = draw_points(img_out, eyes_midpoint, \"eyes_midpoint\")\n",
        "img_out = draw_points(img_out, chin, \"chin\")\n",
        "img_out = draw_points(img_out, contour, \"contour\")\n",
        "plt.imshow(cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdUJAEHpYizi"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Fit ellipse to selected landmark points\n",
        "if alpha > 0.0:\n",
        "    chin_midpoint_vector = eyes_midpoint - chin\n",
        "    top_of_forehead = eyes_midpoint + alpha * chin_midpoint_vector\n",
        "\n",
        "    ellipse_points = np.concatenate([contour, chin, top_of_forehead])\n",
        "    ellipse_points = np.array(ellipse_points, dtype=np.int32)\n",
        "    fitted_ellipse = cv2.fitEllipse(ellipse_points)\n",
        "    center = (int(fitted_ellipse[0][0]), int(fitted_ellipse[0][1]))  # Ellipse center (x, y)\n",
        "    axes = (\n",
        "        int(fitted_ellipse[1][0] / 2),\n",
        "        int(fitted_ellipse[1][1] / 2),\n",
        "    )  # Semi-major and semi-minor axes\n",
        "    angle = int(fitted_ellipse[2])  # Rotation angle\n",
        "    poly_points = cv2.ellipse2Poly(center, axes, angle, 0, 360, 10)\n",
        "\n",
        "    # Discard ellipse points which are not on forehead\n",
        "    poly_points_list = []\n",
        "    chin_midpoint_vector = chin_midpoint_vector.squeeze()\n",
        "    for p in poly_points:\n",
        "        if np.dot(p - chin, chin_midpoint_vector) > 1.1 * np.dot(\n",
        "            chin_midpoint_vector, chin_midpoint_vector\n",
        "        ):\n",
        "            poly_points_list.append(p)\n",
        "    poly_points = np.array(poly_points_list, dtype=np.int32)\n",
        "\n",
        "    # Add poly_points to landmark points\n",
        "    # landmarks = np.concatenate([landmarks, poly_points])\n",
        "    landmarks = landmarks.astype(\"int\")\n",
        "\n",
        "    # Drawing function\n",
        "    img_out = draw_points(deepcopy(img), poly_points, \"elips\")\n",
        "    plt.imshow(cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7CYMPZ7Yizi"
      },
      "outputs": [],
      "source": [
        "# Compute convex hull from selection of landmarks\n",
        "\n",
        "# Fit convex hull\n",
        "hull_points = cv2.convexHull(landmarks).squeeze()\n",
        "\n",
        "# Drawing function\n",
        "img_hullpoints = draw_points(deepcopy(img), hull_points, \"hl\")\n",
        "plt.imshow(cv2.cvtColor(img_hullpoints, cv2.COLOR_BGR2RGB))\n",
        "plt.savefig(\"../output/02_convex_hull.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDpOiyVCYizi"
      },
      "outputs": [],
      "source": [
        "# Convert hull points to 224x224 mask\n",
        "\n",
        "rect = cv2.boundingRect(hull_points)\n",
        "rect_x, rect_y, rect_width, rect_height = rect\n",
        "\n",
        "b = int(rect_y - rect_height * 0.05)\n",
        "d = int(rect_y + rect_height * 1.05)\n",
        "a = int(rect_x + rect_width / 2.0 - (d - b) / 2.0)\n",
        "c = int(rect_x + rect_width / 2.0 + (d - b) / 2.0)\n",
        "\n",
        "# Compute relative landmarks on cropped image\n",
        "img_size = 224\n",
        "hull_point_list = []\n",
        "for idx in range(len(hull_points)):\n",
        "    point = hull_points[idx]\n",
        "    point = (point - np.array([a, b])) / (d - b) * img_size\n",
        "    hull_point_list.append(point)\n",
        "hull_points = np.array(hull_point_list, dtype=np.int32)\n",
        "\n",
        "# Generate mask from convex hull\n",
        "mask = np.zeros((img_size, img_size), dtype=np.uint8)\n",
        "cv2.fillConvexPoly(mask, np.array(hull_points, dtype=np.int32), 1)\n",
        "\n",
        "# Show mask\n",
        "plt.imshow(mask, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJsD6a-OYizi"
      },
      "outputs": [],
      "source": [
        "# Resize mask to original size of input image\n",
        "\n",
        "face_region = np.zeros((height, width), dtype=np.uint8)\n",
        "mask_rescaled = cv2.resize(mask, (c - a, d - b), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "left, top, right, bottom = 0, 0, mask_rescaled.shape[0], mask_rescaled.shape[1]\n",
        "an, bn, cn, dn = a, b, c, d\n",
        "\n",
        "if a < 0:\n",
        "    left -= a\n",
        "    an = 0\n",
        "if c > width:\n",
        "    right -= c - width\n",
        "    cn = width\n",
        "if b < 0:\n",
        "    top -= b\n",
        "    bn = 0\n",
        "if d > height:\n",
        "    bottom -= d - height\n",
        "    dn = height\n",
        "\n",
        "crop = mask_rescaled[top:bottom, left:right]\n",
        "face_region[bn:dn, an:cn] = crop\n",
        "\n",
        "# Show mask\n",
        "plt.imshow(face_region, cmap=\"grey\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9EZVH7HYizi"
      },
      "source": [
        "### Addition: Blend mask on input image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00S0RHP6Yizi"
      },
      "outputs": [],
      "source": [
        "# Plot face_mask on img\n",
        "face_mask = face_region\n",
        "face_mask = cv2.cvtColor(face_mask, cv2.COLOR_GRAY2BGR)  # Extend face_mask channels\n",
        "face_mask[:, :, 2] = face_mask[:, :, 2] * 120.0\n",
        "img_rgb = cv2.cvtColor(deepcopy(img), cv2.COLOR_BGR2RGB)\n",
        "img_mask = cv2.addWeighted(img_rgb, 0.7, face_mask, 0.3, 0.0)\n",
        "\n",
        "plt.imshow(img_mask)\n",
        "plt.savefig(\"../output/03_mask_on_img.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2RrD858Yizi"
      },
      "outputs": [],
      "source": [
        "# Create subplot with all steps\n",
        "from typing import List\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
        "axs: List[plt.Axes] = np.ravel(axs)\n",
        "\n",
        "for ax in axs:\n",
        "    ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
        "\n",
        "axs[0].imshow(cv2.cvtColor(img_landmarks, cv2.COLOR_BGR2RGB))\n",
        "axs[0].set_title(\"ADNet Landmarks\")\n",
        "axs[1].imshow(cv2.cvtColor(img_hullpoints, cv2.COLOR_BGR2RGB))\n",
        "axs[1].set_title(\"OpenCV convexHull\")\n",
        "axs[2].imshow(img_mask)\n",
        "axs[2].set_title(\"Landmarked Region\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"../output/ofiq_convexHull.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBBGRp5GYizj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fdetect",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}