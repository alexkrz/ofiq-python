{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to visualize computation of Landmarked Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.adnet import compute_landmarks\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p = \"../data/ColorFERET-00472_940519_hr_small_cropped.png\"\n",
    "model_p = \"../checkpoints/adnet/adnet_ofiq.onnx\"\n",
    "landmarks = compute_landmarks(img_p, model_p)\n",
    "# print(landmarks.shape)\n",
    "\n",
    "# Helper function\n",
    "\n",
    "\n",
    "def draw_points(img: np.ndarray, points: np.ndarray, name: str = \"default\"):\n",
    "    for idx in range(len(points)):\n",
    "        x, y = points[idx]\n",
    "        cv2.circle(img, (x, y), 3, (255, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(img, name, (x + 2, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "    return img\n",
    "\n",
    "\n",
    "# Show computed landmarks\n",
    "img = cv2.imread(img_p)\n",
    "width, height, channels = img.shape\n",
    "img_landmarks = deepcopy(img)\n",
    "for idx in range(len(landmarks)):\n",
    "    x, y = landmarks[idx]\n",
    "    cv2.circle(img_landmarks, (x, y), 3, (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(img_landmarks, str(idx), (x + 2, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "plt.imshow(cv2.cvtColor(img_landmarks, cv2.COLOR_BGR2RGB))\n",
    "plt.savefig(\"../output/01_landmarks.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down GetFaceMask() function into individual parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Select eyes_midpoint, chin and contour landmarks\n",
    "\n",
    "alpha = 0.0\n",
    "width, height, channels = img.shape\n",
    "\n",
    "left_eye_corners = np.stack([landmarks[60], landmarks[64]])\n",
    "right_eye_corners = np.stack([landmarks[68], landmarks[72]])\n",
    "\n",
    "eye_corners = np.concatenate([left_eye_corners, right_eye_corners])\n",
    "eyes_midpoint = np.sum(eye_corners, axis=0) / len(eye_corners)\n",
    "eyes_midpoint = eyes_midpoint.astype(\"int\")\n",
    "eyes_midpoint = eyes_midpoint[None, :]  # Add extra dimension\n",
    "\n",
    "chin = landmarks[16]\n",
    "chin = chin[None, :]  # Add extra dimension\n",
    "contour_indices = [0, 7, 25, 32]\n",
    "contour_points = []\n",
    "for idx in contour_indices:\n",
    "    contour_points.append(landmarks[idx])\n",
    "contour = np.array(contour_points)\n",
    "\n",
    "# Drawing function\n",
    "img_out = deepcopy(img)\n",
    "img_out = draw_points(img_out, eyes_midpoint, \"eyes_midpoint\")\n",
    "img_out = draw_points(img_out, chin, \"chin\")\n",
    "img_out = draw_points(img_out, contour, \"contour\")\n",
    "plt.imshow(cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Fit ellipse to selected landmark points\n",
    "if alpha > 0.0:\n",
    "    chin_midpoint_vector = eyes_midpoint - chin\n",
    "    top_of_forehead = eyes_midpoint + alpha * chin_midpoint_vector\n",
    "\n",
    "    ellipse_points = np.concatenate([contour, chin, top_of_forehead])\n",
    "    ellipse_points = np.array(ellipse_points, dtype=np.int32)\n",
    "    fitted_ellipse = cv2.fitEllipse(ellipse_points)\n",
    "    center = (int(fitted_ellipse[0][0]), int(fitted_ellipse[0][1]))  # Ellipse center (x, y)\n",
    "    axes = (\n",
    "        int(fitted_ellipse[1][0] / 2),\n",
    "        int(fitted_ellipse[1][1] / 2),\n",
    "    )  # Semi-major and semi-minor axes\n",
    "    angle = int(fitted_ellipse[2])  # Rotation angle\n",
    "    poly_points = cv2.ellipse2Poly(center, axes, angle, 0, 360, 10)\n",
    "\n",
    "    # Discard ellipse points which are not on forehead\n",
    "    poly_points_list = []\n",
    "    chin_midpoint_vector = chin_midpoint_vector.squeeze()\n",
    "    for p in poly_points:\n",
    "        if np.dot(p - chin, chin_midpoint_vector) > 1.1 * np.dot(\n",
    "            chin_midpoint_vector, chin_midpoint_vector\n",
    "        ):\n",
    "            poly_points_list.append(p)\n",
    "    poly_points = np.array(poly_points_list, dtype=np.int32)\n",
    "\n",
    "    # Add poly_points to landmark points\n",
    "    # landmarks = np.concatenate([landmarks, poly_points])\n",
    "    landmarks = landmarks.astype(\"int\")\n",
    "\n",
    "    # Drawing function\n",
    "    img_out = draw_points(deepcopy(img), poly_points, \"elips\")\n",
    "    plt.imshow(cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute convex hull from selection of landmarks\n",
    "\n",
    "# Fit convex hull\n",
    "hull_points = cv2.convexHull(landmarks).squeeze()\n",
    "\n",
    "# Drawing function\n",
    "img_hullpoints = draw_points(deepcopy(img), hull_points, \"hl\")\n",
    "plt.imshow(cv2.cvtColor(img_hullpoints, cv2.COLOR_BGR2RGB))\n",
    "plt.savefig(\"../output/02_convex_hull.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hull points to 224x224 mask\n",
    "\n",
    "rect = cv2.boundingRect(hull_points)\n",
    "rect_x, rect_y, rect_width, rect_height = rect\n",
    "\n",
    "b = int(rect_y - rect_height * 0.05)\n",
    "d = int(rect_y + rect_height * 1.05)\n",
    "a = int(rect_x + rect_width / 2.0 - (d - b) / 2.0)\n",
    "c = int(rect_x + rect_width / 2.0 + (d - b) / 2.0)\n",
    "\n",
    "# Compute relative landmarks on cropped image\n",
    "img_size = 224\n",
    "hull_point_list = []\n",
    "for idx in range(len(hull_points)):\n",
    "    point = hull_points[idx]\n",
    "    point = (point - np.array([a, b])) / (d - b) * img_size\n",
    "    hull_point_list.append(point)\n",
    "hull_points = np.array(hull_point_list, dtype=np.int32)\n",
    "\n",
    "# Generate mask from convex hull\n",
    "mask = np.zeros((img_size, img_size), dtype=np.uint8)\n",
    "cv2.fillConvexPoly(mask, np.array(hull_points, dtype=np.int32), 1)\n",
    "\n",
    "# Show mask\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize mask to original size of input image\n",
    "\n",
    "face_region = np.zeros((height, width), dtype=np.uint8)\n",
    "mask_rescaled = cv2.resize(mask, (c - a, d - b), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "left, top, right, bottom = 0, 0, mask_rescaled.shape[0], mask_rescaled.shape[1]\n",
    "an, bn, cn, dn = a, b, c, d\n",
    "\n",
    "if a < 0:\n",
    "    left -= a\n",
    "    an = 0\n",
    "if c > width:\n",
    "    right -= c - width\n",
    "    cn = width\n",
    "if b < 0:\n",
    "    top -= b\n",
    "    bn = 0\n",
    "if d > height:\n",
    "    bottom -= d - height\n",
    "    dn = height\n",
    "\n",
    "crop = mask_rescaled[top:bottom, left:right]\n",
    "face_region[bn:dn, an:cn] = crop\n",
    "\n",
    "# Show mask\n",
    "plt.imshow(face_region, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition: Blend mask on input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot face_mask on img\n",
    "face_mask = face_region\n",
    "face_mask = cv2.cvtColor(face_mask, cv2.COLOR_GRAY2BGR)  # Extend face_mask channels\n",
    "face_mask[:, :, 2] = face_mask[:, :, 2] * 120.0\n",
    "img_rgb = cv2.cvtColor(deepcopy(img), cv2.COLOR_BGR2RGB)\n",
    "img_mask = cv2.addWeighted(img_rgb, 0.7, face_mask, 0.3, 0.0)\n",
    "\n",
    "plt.imshow(img_mask)\n",
    "plt.savefig(\"../output/03_mask_on_img.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplot with all steps\n",
    "from typing import List\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
    "axs: List[plt.Axes] = np.ravel(axs)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "axs[0].imshow(cv2.cvtColor(img_landmarks, cv2.COLOR_BGR2RGB))\n",
    "axs[0].set_title(\"ADNet Landmarks\")\n",
    "axs[1].imshow(cv2.cvtColor(img_hullpoints, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title(\"OpenCV convexHull\")\n",
    "axs[2].imshow(img_mask)\n",
    "axs[2].set_title(\"Landmarked Region\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/ofiq_convexHull.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdetect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
